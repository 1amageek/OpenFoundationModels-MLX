import Testing
@testable import OpenFoundationModelsMLX

@Suite struct TokenTriePerformanceTests {
    
    // MARK: - Mock Tokenizer with Configurable Vocabulary
    
    struct PerformanceTokenizer: TokenizerAdapter {
        let vocabSize: Int
        
        init(vocabSize: Int = 50000) {
            self.vocabSize = vocabSize
        }
        
        func encode(_ text: String) -> [Int32] {
            // Create deterministic but varied token sequences
            var tokens: [Int32] = []
            var hash: UInt32 = 5381 // DJB2 hash start
            
            for char in text.utf8 {
                hash = ((hash << 5) &+ hash) &+ UInt32(char)
                tokens.append(Int32(hash % UInt32(vocabSize)))
            }
            
            // Ensure non-empty result for non-empty input
            if text.isEmpty {
                return []
            } else if tokens.isEmpty {
                return [1] // Fallback
            }
            
            return tokens
        }
        
        func decode(_ ids: [Int32]) -> String {
            // Simple deterministic decode - not realistic but sufficient for testing
            return ids.map { String($0) }.joined(separator: "_")
        }
        
        func getVocabSize() -> Int? {
            return vocabSize
        }
    }
    
    // MARK: - Insertion Performance Tests
    
    @Suite struct InsertionPerformanceTests {
        
        @Test func measureBulkInsertionPerformance() {
            let tokenizer = PerformanceTokenizer()
            let keyCount = 10000
            let keys = (1...keyCount).map { "key_\($0)_with_some_length_variation" }
            
            let startTime = CFAbsoluteTimeGetCurrent()
            let trie = TokenTrieBuilder.build(keys: keys, tokenizer: tokenizer)
            let buildTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.count == keyCount)
            
            // Performance assertion - should complete within reasonable time
            // Adjust threshold based on expected performance characteristics
            #expect(buildTime < 10.0, "Bulk insertion took \(buildTime) seconds, expected < 10s")
            
            print("Built trie with \(keyCount) keys in \(buildTime) seconds")
        }
        
        @Test func measureSequentialInsertions() {
            var trie = TokenTrie()
            let tokenizer = PerformanceTokenizer()
            let keyCount = 5000
            
            let startTime = CFAbsoluteTimeGetCurrent()
            
            for i in 1...keyCount {
                let key = "sequential_key_\(i)"
                let tokens = tokenizer.encode(key)
                trie.insert(tokenIDs: tokens, keyName: key)
            }
            
            let insertTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.count == keyCount)
            #expect(insertTime < 5.0, "Sequential insertions took \(insertTime) seconds, expected < 5s")
            
            print("Sequential insertion of \(keyCount) keys took \(insertTime) seconds")
        }
        
        @Test func measureLongSequenceInsertion() {
            var trie = TokenTrie()
            let tokenizer = PerformanceTokenizer()
            
            // Very long key - 1000 characters
            let longKey = String(repeating: "abcdefghij", count: 100)
            let tokens = tokenizer.encode(longKey)
            
            let startTime = CFAbsoluteTimeGetCurrent()
            trie.insert(tokenIDs: tokens, keyName: longKey)
            let insertTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.contains(longKey))
            #expect(insertTime < 1.0, "Long sequence insertion took \(insertTime) seconds, expected < 1s")
            
            print("Long sequence (\(tokens.count) tokens) insertion took \(insertTime) seconds")
        }
    }
    
    // MARK: - Lookup Performance Tests
    
    @Suite struct LookupPerformanceTests {
        
        func createLargeTrie() -> (TokenTrie, PerformanceTokenizer) {
            let tokenizer = PerformanceTokenizer()
            let keys = (1...5000).map { "lookup_key_\($0)_with_variable_length_\(String(repeating: "x", count: $0 % 20))" }
            let trie = TokenTrieBuilder.build(keys: keys, tokenizer: tokenizer)
            return (trie, tokenizer)
        }
        
        @Test func measureNodeLookupPerformance() {
            let (trie, tokenizer) = createLargeTrie()
            
            // Test various paths
            let testKeys = ["lookup_key_100_with_variable_length_", 
                          "lookup_key_2500_with_variable_length_xxxxx",
                          "lookup_key_5000_with_variable_length_"]
            
            let startTime = CFAbsoluteTimeGetCurrent()
            
            for _ in 1...1000 { // Repeat lookups to measure performance
                for key in testKeys {
                    let tokens = tokenizer.encode(key)
                    let node = trie.node(for: tokens)
                    #expect(node?.terminal == true)
                }
            }
            
            let lookupTime = CFAbsoluteTimeGetCurrent() - startTime
            #expect(lookupTime < 2.0, "Node lookups took \(lookupTime) seconds, expected < 2s")
            
            print("1000 lookup iterations took \(lookupTime) seconds")
        }
        
        @Test func measureAllowedTokensPerformance() {
            let (trie, _) = createLargeTrie()
            
            let startTime = CFAbsoluteTimeGetCurrent()
            
            // Test allowed tokens computation at various depths
            for _ in 1...1000 {
                let _ = trie.allowedNext(from: [])  // Root
                let _ = trie.allowedNext(from: [100])  // Depth 1
                let _ = trie.allowedNext(from: [100, 200])  // Depth 2
                let _ = trie.allowedNext(from: [100, 200, 300])  // Depth 3
            }
            
            let computeTime = CFAbsoluteTimeGetCurrent() - startTime
            #expect(computeTime < 1.0, "Allowed tokens computation took \(computeTime) seconds, expected < 1s")
            
            print("1000 allowed tokens computations took \(computeTime) seconds")
        }
        
        @Test func measurePathTraversalPerformance() {
            let (trie, tokenizer) = createLargeTrie()
            
            // Create a long valid path
            let testKey = "lookup_key_1000_with_variable_length_"
            let tokens = tokenizer.encode(testKey)
            
            let startTime = CFAbsoluteTimeGetCurrent()
            
            for _ in 1...500 { // Repeat path traversals
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    let success = path.append(token, in: trie)
                    #expect(success == true)
                }
                #expect(path.isAtTerminal())
            }
            
            let traversalTime = CFAbsoluteTimeGetCurrent() - startTime
            #expect(traversalTime < 2.0, "Path traversals took \(traversalTime) seconds, expected < 2s")
            
            print("500 path traversals (\(tokens.count) tokens each) took \(traversalTime) seconds")
        }
    }
    
    // MARK: - Memory Usage Tests
    
    @Suite struct MemoryUsageTests {
        
        @Test func measureMemoryFootprint() {
            let tokenizer = PerformanceTokenizer()
            
            // Build increasingly large tries and measure growth
            let sizes = [100, 1000, 5000, 10000]
            
            for size in sizes {
                let keys = (1...size).map { "memory_key_\($0)" }
                
                autoreleasepool {
                    let trie = TokenTrieBuilder.build(keys: keys, tokenizer: tokenizer)
                    #expect(trie.allKeys.count == size)
                    
                    // Rough memory usage validation - trie should exist and be functional
                    let sampleKey = "memory_key_\(size/2)"
                    let sampleTokens = tokenizer.encode(sampleKey)
                    #expect(trie.node(for: sampleTokens)?.terminal == true)
                    
                    print("Trie with \(size) keys created successfully")
                }
            }
        }
        
        @Test func measureCacheEfficiency() {
            let tokenizer = PerformanceTokenizer()
            let schema = SchemaMeta(keys: ["cached_key_1", "cached_key_2"], required: [])
            
            // First build should take longer (cache miss)
            let startTime1 = CFAbsoluteTimeGetCurrent()
            let trie1 = TokenTrieBuilder.buildCached(schema: schema, tokenizer: tokenizer)
            let buildTime1 = CFAbsoluteTimeGetCurrent() - startTime1
            
            // Second build should be faster (cache hit)
            let startTime2 = CFAbsoluteTimeGetCurrent()
            let trie2 = TokenTrieBuilder.buildCached(schema: schema, tokenizer: tokenizer)
            let buildTime2 = CFAbsoluteTimeGetCurrent() - startTime2
            
            #expect(trie1.allKeys == trie2.allKeys)
            
            print("First build: \(buildTime1)s, Second build (cached): \(buildTime2)s")
            
            // Cache should provide significant speedup for repeated builds
            // Note: This test might be flaky on very fast systems where both times are near zero
            if buildTime1 > 0.001 {
                #expect(buildTime2 < buildTime1, "Cached build should be faster")
            }
        }
    }
    
    // MARK: - Stress Tests
    
    @Suite struct StressTests {
        
        @Test(.disabled("Stress test - enable for thorough testing")) 
        func stressTestMassiveInsertion() {
            let tokenizer = PerformanceTokenizer(vocabSize: 100000)
            let keyCount = 50000
            
            let keys = (1...keyCount).map { i in
                "stress_key_\(i)_\(String(repeating: "abcdef", count: i % 10 + 1))"
            }
            
            let startTime = CFAbsoluteTimeGetCurrent()
            let trie = TokenTrieBuilder.build(keys: keys, tokenizer: tokenizer)
            let buildTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.count == keyCount)
            print("Stress test: Built trie with \(keyCount) keys in \(buildTime) seconds")
            
            // Validate a sample of keys
            let sampleSize = min(100, keyCount)
            for i in stride(from: 1, to: keyCount, by: keyCount / sampleSize) {
                let key = "stress_key_\(i)_\(String(repeating: "abcdef", count: i % 10 + 1))"
                let tokens = tokenizer.encode(key)
                #expect(trie.node(for: tokens)?.terminal == true)
            }
        }
        
        @Test(.disabled("Stress test - enable for thorough testing"))
        func stressTestDeepNesting() {
            var trie = TokenTrie()
            let maxDepth = 1000
            
            // Create increasingly deep paths
            for depth in 1...maxDepth {
                let tokens = Array(1...depth).map { Int32($0) }
                trie.insert(tokenIDs: tokens, keyName: "depth_\(depth)")
            }
            
            #expect(trie.allKeys.count == maxDepth)
            
            // Validate deepest path
            let deepestTokens = Array(1...maxDepth).map { Int32($0) }
            #expect(trie.node(for: deepestTokens)?.terminal == true)
            #expect(trie.node(for: deepestTokens)?.keyName == "depth_\(maxDepth)")
            
            print("Stress test: Created trie with maximum depth \(maxDepth)")
        }
        
        @Test(.disabled("Stress test - enable for thorough testing"))
        func stressTestWideBranching() {
            var trie = TokenTrie()
            let branchWidth = 10000
            
            // Create very wide branching at root
            for i in 1...branchWidth {
                trie.insert(tokenIDs: [Int32(i), Int32(i + 100000)], keyName: "branch_\(i)")
            }
            
            #expect(trie.allKeys.count == branchWidth)
            
            // Root should have branchWidth children
            let rootResult = trie.allowedNext(from: [])
            #expect(rootResult?.ids.count == branchWidth)
            
            print("Stress test: Created trie with \(branchWidth) branches from root")
        }
    }
    
    // MARK: - Real-world Scenario Performance Tests
    
    @Suite struct RealWorldScenarioTests {
        
        @Test func jsonSchemaPerformance() {
            let tokenizer = PerformanceTokenizer()
            
            // Simulate common JSON schema keys
            let commonKeys = [
                "id", "name", "email", "age", "address", "city", "state", "zip",
                "phone", "website", "company", "title", "department", "salary",
                "start_date", "end_date", "status", "created_at", "updated_at",
                "first_name", "last_name", "middle_name", "date_of_birth",
                "social_security", "emergency_contact", "skills", "education",
                "experience", "certifications", "languages", "references"
            ]
            
            let startTime = CFAbsoluteTimeGetCurrent()
            let trie = TokenTrieBuilder.build(keys: commonKeys, tokenizer: tokenizer)
            let buildTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.count == commonKeys.count)
            #expect(buildTime < 0.1, "JSON schema trie build took \(buildTime) seconds, expected < 0.1s")
            
            // Simulate constraint checking during generation
            let constraintStartTime = CFAbsoluteTimeGetCurrent()
            
            for _ in 1...1000 {
                // Simulate token-by-token generation
                var path = TokenTrie.Path(root: trie.root)
                let testKey = commonKeys.randomElement()!
                let tokens = tokenizer.encode(testKey)
                
                for token in tokens {
                    let success = path.append(token, in: trie)
                    if !success { break }
                }
            }
            
            let constraintTime = CFAbsoluteTimeGetCurrent() - constraintStartTime
            #expect(constraintTime < 1.0, "Constraint checking took \(constraintTime) seconds, expected < 1s")
            
            print("JSON schema performance: Build \(buildTime)s, Constraint checking \(constraintTime)s")
        }
        
        @Test func apiResponseSchemaPerformance() {
            let tokenizer = PerformanceTokenizer()
            
            // Simulate nested API response structure keys
            let apiKeys = [
                "data", "status", "message", "code", "timestamp",
                "user", "user_id", "username", "user_email", "user_profile",
                "items", "item_id", "item_name", "item_description", "item_price",
                "metadata", "pagination", "page", "limit", "total", "has_more",
                "errors", "error_code", "error_message", "error_details",
                "settings", "preferences", "notifications", "permissions"
            ]
            
            // Add nested variations
            let nestedKeys = apiKeys.flatMap { base in
                ["nested_\(base)", "inner_\(base)", "sub_\(base)"]
            }
            
            let allKeys = apiKeys + nestedKeys
            
            let startTime = CFAbsoluteTimeGetCurrent()
            let trie = TokenTrieBuilder.build(keys: allKeys, tokenizer: tokenizer)
            let buildTime = CFAbsoluteTimeGetCurrent() - startTime
            
            #expect(trie.allKeys.count == allKeys.count)
            #expect(buildTime < 0.5, "API schema trie build took \(buildTime) seconds, expected < 0.5s")
            
            print("API response schema performance: Build \(buildTime)s for \(allKeys.count) keys")
        }
    }
}
