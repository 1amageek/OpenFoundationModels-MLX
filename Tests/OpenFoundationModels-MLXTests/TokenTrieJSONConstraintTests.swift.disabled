import Testing
@testable import OpenFoundationModelsMLX

@Suite struct TokenTrieJSONConstraintTests {
    
    // MARK: - JSON-Aware Mock Tokenizer
    
    /// JSON-aware tokenizer that properly handles JSON special characters
    struct JSONTokenizer: TokenizerAdapter {
        private let tokenMap: [String: Int32]
        private let reverseTokenMap: [Int32: String]
        
        init() {
            var tokenMap: [String: Int32] = [:]
            var reverseTokenMap: [Int32: String] = [:]
            var tokenId: Int32 = 1
            
            // JSON structural tokens
            let jsonStructural = ["\"", ":", "{", "}", ",", "[", "]", " ", "\n", "\t", "true", "false", "null"]
            for token in jsonStructural {
                tokenMap[token] = tokenId
                reverseTokenMap[tokenId] = token
                tokenId += 1
            }
            
            // Common JSON key patterns
            let jsonKeys = ["name", "age", "email", "id", "type", "value", "data", "status", "message",
                          "user", "item", "list", "count", "index", "key", "result", "error",
                          "first", "last", "middle", "start", "end", "created", "updated"]
            
            for key in jsonKeys {
                // Quoted versions (common in JSON)
                tokenMap["\"\(key)\""] = tokenId
                reverseTokenMap[tokenId] = "\"\(key)\""
                tokenId += 1
                
                // Unquoted versions
                tokenMap[key] = tokenId
                reverseTokenMap[tokenId] = key
                tokenId += 1
                
                // Snake_case versions
                tokenMap["\(key)_"] = tokenId
                reverseTokenMap[tokenId] = "\(key)_"
                tokenId += 1
                
                tokenMap["_\(key)"] = tokenId
                reverseTokenMap[tokenId] = "_\(key)"
                tokenId += 1
            }
            
            // Numbers as strings (JSON values)
            for i in 0...100 {
                let numStr = String(i)
                tokenMap[numStr] = tokenId
                reverseTokenMap[tokenId] = numStr
                tokenId += 1
            }
            
            // Single characters for fallback
            for i in 32...126 {
                let char = String(Character(UnicodeScalar(i)!))
                if tokenMap[char] == nil {
                    tokenMap[char] = tokenId
                    reverseTokenMap[tokenId] = char
                    tokenId += 1
                }
            }
            
            self.tokenMap = tokenMap
            self.reverseTokenMap = reverseTokenMap
        }
        
        func encode(_ text: String) -> [Int32] {
            var tokens: [Int32] = []
            var i = text.startIndex
            
            while i < text.endIndex {
                var found = false
                
                // Try longest match first (greedy tokenization)
                for length in (1...min(50, text.distance(from: i, to: text.endIndex))).reversed() {
                    let endIndex = text.index(i, offsetBy: length, limitedBy: text.endIndex) ?? text.endIndex
                    let substring = String(text[i..<endIndex])
                    
                    if let tokenId = tokenMap[substring] {
                        tokens.append(tokenId)
                        i = endIndex
                        found = true
                        break
                    }
                }
                
                if !found {
                    // Fallback to single character
                    let char = String(text[i])
                    if let tokenId = tokenMap[char] {
                        tokens.append(tokenId)
                    } else {
                        tokens.append(999999) // Unknown token
                    }
                    i = text.index(after: i)
                }
            }
            
            return tokens
        }
        
        func decode(_ ids: [Int32]) -> String {
            return ids.compactMap { reverseTokenMap[$0] }.joined()
        }
        
        func getVocabSize() -> Int? {
            return tokenMap.count
        }
    }
    
    // MARK: - Basic JSON Constraint Tests
    
    @Suite struct BasicJSONConstraintTests {
        
        @Test func constrainsSimpleJSONKeys() {
            let tokenizer = JSONTokenizer()
            let jsonKeys = ["name", "age", "email"]
            let trie = TokenTrieBuilder.build(keys: jsonKeys, tokenizer: tokenizer)
            
            #expect(trie.allKeys == Set(jsonKeys))
            
            // Test that each key can be generated under JSON constraints
            for key in jsonKeys {
                let tokens = tokenizer.encode(key)
                #expect(!tokens.isEmpty, "Key '\(key)' produced empty tokens")
                
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Key '\(key)' is not terminal")
                #expect(node?.keyName == key, "Key name mismatch for '\(key)'")
            }
        }
        
        @Test func constrainsQuotedJSONKeys() {
            let tokenizer = JSONTokenizer()
            
            // Keys as they would appear in JSON (with quotes)
            let quotedKeys = ["\"name\"", "\"age\"", "\"email\"", "\"isActive\""]
            let trie = TokenTrieBuilder.build(keys: quotedKeys, tokenizer: tokenizer)
            
            #expect(trie.allKeys == Set(quotedKeys))
            
            for key in quotedKeys {
                let tokens = tokenizer.encode(key)
                
                // Should handle quoted keys properly
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Quoted key '\(key)' is not terminal")
                #expect(node?.keyName == key)
                
                // Test path traversal for quoted keys
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    #expect(path.append(token, in: trie), "Cannot append token \(token) for quoted key '\(key)'")
                }
                #expect(path.isAtTerminal())
            }
        }
        
        @Test func handlesJSONSpecialCharacters() {
            let tokenizer = JSONTokenizer()
            
            // Keys containing JSON special characters
            let specialKeys = ["user_name", "user-id", "email@domain", "key:value", "item[0]"]
            let trie = TokenTrieBuilder.build(keys: specialKeys, tokenizer: tokenizer)
            
            for key in specialKeys {
                let tokens = tokenizer.encode(key)
                #expect(!tokens.isEmpty, "Special key '\(key)' encoded to empty tokens")
                
                // Verify round-trip
                let decoded = tokenizer.decode(tokens)
                #expect(decoded == key, "Round-trip failed: '\(key)' -> '\(decoded)'")
                
                // Verify trie contains the key
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Special key '\(key)' not found in trie")
            }
        }
        
        @Test func constrainsNestedJSONKeys() {
            let tokenizer = JSONTokenizer()
            
            // Simulate nested JSON object keys
            let nestedKeys = [
                "user",
                "user.name", 
                "user.profile",
                "user.profile.firstName",
                "user.settings",
                "user.settings.theme",
                "user.settings.notifications"
            ]
            
            let trie = TokenTrieBuilder.build(keys: nestedKeys, tokenizer: tokenizer)
            
            #expect(trie.allKeys == Set(nestedKeys))
            
            // Test that nested structure allows proper navigation
            for key in nestedKeys {
                let tokens = tokenizer.encode(key)
                var path = TokenTrie.Path(root: trie.root)
                
                for token in tokens {
                    let allowedTokens = trie.getAllowedTokens(for: path)
                    #expect(allowedTokens.contains(token), "Token \(token) not allowed for nested key '\(key)'")
                    #expect(path.append(token, in: trie))
                }
                
                #expect(path.isAtTerminal(), "Nested key '\(key)' path is not terminal")
                #expect(path.getKeyName() == key)
            }
        }
    }
    
    // MARK: - JSON Schema Constraint Tests
    
    @Suite struct JSONSchemaConstraintTests {
        
        @Test func enforcesRequiredKeys() {
            let tokenizer = JSONTokenizer()
            
            let schema = SchemaMeta(
                keys: ["id", "name", "email", "age", "isActive"],
                required: ["id", "name", "email"]
            )
            
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            // All schema keys should be in trie
            for key in schema.keys {
                #expect(trie.allKeys.contains(key), "Schema key '\(key)' missing from trie")
            }
            
            // Required keys should be accessible
            for requiredKey in schema.required {
                let tokens = tokenizer.encode(requiredKey)
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Required key '\(requiredKey)' not terminal in trie")
            }
            
            // Should be able to generate all required keys in sequence
            var combinedPath = TokenTrie.Path(root: trie.root)
            
            for requiredKey in schema.required {
                let tokens = tokenizer.encode(requiredKey)
                
                // Reset path for each key (simulating new key generation)
                combinedPath.reset(to: trie.root)
                
                for token in tokens {
                    let allowedTokens = trie.getAllowedTokens(for: combinedPath)
                    #expect(allowedTokens.contains(token), "Required key '\(requiredKey)' token \(token) not allowed")
                    #expect(combinedPath.append(token, in: trie))
                }
            }
        }
        
        @Test func handlesOptionalKeys() {
            let tokenizer = JSONTokenizer()
            
            let schema = SchemaMeta(
                keys: ["id", "name", "email", "phone", "address", "bio"],
                required: ["id", "name"] // phone, address, bio are optional
            )
            
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            // Optional keys should also be constrainable
            let optionalKeys = Set(schema.keys).subtracting(Set(schema.required))
            
            for optionalKey in optionalKeys {
                let tokens = tokenizer.encode(optionalKey)
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Optional key '\(optionalKey)' not accessible in trie")
                
                // Should be able to generate optional keys
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    #expect(path.append(token, in: trie), "Cannot generate optional key '\(optionalKey)'")
                }
                #expect(path.isAtTerminal())
            }
        }
        
        @Test func constrainsTypedKeys() {
            let tokenizer = JSONTokenizer()
            
            // Keys with implied types based on naming conventions
            let typedKeys = [
                "id",           // typically number or string
                "name",         // string
                "email",        // string with format
                "age",          // number
                "isActive",     // boolean
                "tags",         // array
                "profile",      // object
                "created_at",   // datetime string
                "score"         // number
            ]
            
            let schema = SchemaMeta(keys: typedKeys, required: ["id"])
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            // All typed keys should be constrainable
            for key in typedKeys {
                let tokens = tokenizer.encode(key)
                #expect(trie.node(for: tokens)?.terminal == true, "Typed key '\(key)' not constrainable")
                
                // Test constraint generation
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    let allowedTokens = trie.getAllowedTokens(for: path)
                    #expect(!allowedTokens.isEmpty, "No allowed tokens for typed key '\(key)' at token \(token)")
                    #expect(allowedTokens.contains(token), "Token \(token) not allowed for typed key '\(key)'")
                    #expect(path.append(token, in: trie))
                }
            }
        }
    }
    
    // MARK: - JSON Generation Constraint Tests
    
    @Suite struct JSONGenerationConstraintTests {
        
        @Test func constrainsJSONObjectGeneration() {
            let tokenizer = JSONTokenizer()
            
            // Simple JSON object schema
            let objectKeys = ["name", "age", "city"]
            let trie = TokenTrieBuilder.build(keys: objectKeys, tokenizer: tokenizer)
            
            // Simulate JSON object generation: {"name": "...", "age": ..., "city": "..."}
            // TokenTrie should constrain the key parts
            
            for key in objectKeys {
                // Test that key can be generated step by step
                let keyTokens = tokenizer.encode(key)
                var keyPath = TokenTrie.Path(root: trie.root)
                
                for (index, token) in keyTokens.enumerated() {
                    let allowedTokens = trie.getAllowedTokens(for: keyPath)
                    #expect(allowedTokens.contains(token), 
                           "Token \(token) at position \(index) not allowed for JSON key '\(key)'")
                    
                    #expect(keyPath.append(token, in: trie), 
                           "Cannot append token \(token) for JSON key '\(key)'")
                }
                
                #expect(keyPath.isAtTerminal(), "JSON key '\(key)' generation did not reach terminal")
                #expect(keyPath.getKeyName() == key)
            }
        }
        
        @Test func constrainsJSONArrayKeys() {
            let tokenizer = JSONTokenizer()
            
            // Array-like schema
            let arrayKeys = ["items", "data", "results", "list", "entries"]
            let trie = TokenTrieBuilder.build(keys: arrayKeys, tokenizer: tokenizer)
            
            // Arrays in JSON: {"items": [...], "data": [...]}
            for key in arrayKeys {
                let tokens = tokenizer.encode(key)
                var path = TokenTrie.Path(root: trie.root)
                
                for token in tokens {
                    #expect(path.append(token, in: trie), "Cannot generate array key '\(key)'")
                }
                
                #expect(path.isAtTerminal())
                #expect(trie.canComplete(from: path))
            }
        }
        
        @Test func handlesComplexJSONStructures() {
            let tokenizer = JSONTokenizer()
            
            // Complex nested structure
            let complexKeys = [
                "response",
                "response.status", 
                "response.data",
                "response.data.user",
                "response.data.user.id",
                "response.data.user.profile", 
                "response.data.items",
                "response.metadata",
                "response.metadata.pagination",
                "response.metadata.timing"
            ]
            
            let trie = TokenTrieBuilder.build(keys: complexKeys, tokenizer: tokenizer)
            
            // Test complex navigation patterns
            for key in complexKeys {
                let tokens = tokenizer.encode(key)
                #expect(!tokens.isEmpty, "Complex key '\(key)' has no tokens")
                
                var path = TokenTrie.Path(root: trie.root)
                var tokenIndex = 0
                
                for token in tokens {
                    let currentAllowed = trie.getAllowedTokens(for: path)
                    #expect(currentAllowed.contains(token), 
                           "Complex key '\(key)' token \(token) at position \(tokenIndex) not allowed")
                    
                    #expect(path.append(token, in: trie))
                    tokenIndex += 1
                }
                
                #expect(path.isAtTerminal(), "Complex key '\(key)' did not reach terminal")
                #expect(path.getKeyName() == key)
            }
            
            // Test that intermediate paths are properly handled
            let intermediateKey = "response.data"
            let intermediateTokens = tokenizer.encode(intermediateKey)
            let intermediateNode = trie.node(for: intermediateTokens)
            
            #expect(intermediateNode?.terminal == true, "Intermediate key should be terminal")
            
            // Should allow continuation to nested keys
            var intermediatePath = TokenTrie.Path(root: trie.root)
            for token in intermediateTokens {
                #expect(intermediatePath.append(token, in: trie))
            }
            
            let allowedAfterIntermediate = trie.getAllowedTokens(for: intermediatePath)
            #expect(!allowedAfterIntermediate.isEmpty, "Should allow continuation from intermediate key")
        }
    }
    
    // MARK: - JSON Validation Constraint Tests
    
    @Suite struct JSONValidationConstraintTests {
        
        @Test func rejectsInvalidKeys() {
            let tokenizer = JSONTokenizer()
            let validKeys = ["name", "age", "email"]
            let trie = TokenTrieBuilder.build(keys: validKeys, tokenizer: tokenizer)
            
            // Test invalid keys that should not be allowed
            let invalidKeys = ["invalid", "notallowed", "badkey", "wrong"]
            
            for invalidKey in invalidKeys {
                let tokens = tokenizer.encode(invalidKey)
                var path = TokenTrie.Path(root: trie.root)
                var validPath = true
                
                for token in tokens {
                    if !path.append(token, in: trie) {
                        validPath = false
                        break
                    }
                }
                
                // Either the path should be invalid, or if valid, not terminal
                if validPath {
                    #expect(!path.isAtTerminal(), "Invalid key '\(invalidKey)' should not be terminal")
                } else {
                    // Path broke somewhere - this is expected for invalid keys
                    #expect(path.tokens.count < tokens.count, "Invalid key path should be incomplete")
                }
            }
        }
        
        @Test func enforcesExactKeyMatching() {
            let tokenizer = JSONTokenizer()
            let exactKeys = ["user", "userid", "username"] // Similar but distinct keys
            let trie = TokenTrieBuilder.build(keys: exactKeys, tokenizer: tokenizer)
            
            // Test that partial matches don't incorrectly validate
            for key in exactKeys {
                let tokens = tokenizer.encode(key)
                
                // Full key should be valid and terminal
                let fullNode = trie.node(for: tokens)
                #expect(fullNode?.terminal == true, "Exact key '\(key)' should be terminal")
                
                // Partial key should not be terminal (unless it's also a complete key)
                if tokens.count > 1 {
                    let partialTokens = Array(tokens.prefix(tokens.count - 1))
                    let partialNode = trie.node(for: partialTokens)
                    
                    if let node = partialNode {
                        // If partial path exists, it should either not be terminal,
                        // or be terminal only if it matches another complete key
                        if node.terminal {
                            let partialDecoded = tokenizer.decode(partialTokens)
                            #expect(exactKeys.contains(partialDecoded), 
                                   "Partial path '\(partialDecoded)' is terminal but not a valid key")
                        }
                    }
                }
            }
        }
        
        @Test func handlesKeyCollisions() {
            let tokenizer = JSONTokenizer()
            
            // Keys that might have overlapping token sequences
            let overlappingKeys = ["name", "names", "named", "naming"]
            let trie = TokenTrieBuilder.build(keys: overlappingKeys, tokenizer: tokenizer)
            
            #expect(trie.allKeys == Set(overlappingKeys))
            
            // Each key should be individually valid and terminal
            for key in overlappingKeys {
                let tokens = tokenizer.encode(key)
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Overlapping key '\(key)' should be terminal")
                #expect(node?.keyName == key, "Key name should match exactly")
                
                // Test step-by-step generation
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    let allowed = trie.getAllowedTokens(for: path)
                    #expect(allowed.contains(token), "Overlapping key '\(key)' token \(token) not allowed")
                    #expect(path.append(token, in: trie))
                }
                
                #expect(path.isAtTerminal())
                #expect(path.getKeyName() == key)
            }
            
            // Test that common prefixes allow multiple continuations
            let nameTokens = tokenizer.encode("name")
            if nameTokens.count > 0 {
                let afterName = trie.allowedNext(from: nameTokens)
                if let result = afterName {
                    if result.atTerminal {
                        // "name" itself should be terminal
                        #expect(overlappingKeys.contains("name"))
                    }
                    
                    // Should allow continuation to other keys starting with "name"
                    // This depends on the specific tokenization
                }
            }
        }
    }
    
    // MARK: - Real-world JSON Schema Tests
    
    @Suite struct RealWorldJSONSchemaTests {
        
        @Test func apiResponseSchema() {
            let tokenizer = JSONTokenizer()
            
            // Typical API response structure
            let apiKeys = [
                "success", "error", "message", "code", "timestamp",
                "data", "result", "payload",
                "pagination", "page", "limit", "total", "hasMore",
                "meta", "version", "requestId"
            ]
            
            let schema = SchemaMeta(keys: apiKeys, required: ["success", "data"])
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            // Test API response generation constraints
            for key in apiKeys {
                let tokens = tokenizer.encode(key)
                var path = TokenTrie.Path(root: trie.root)
                
                for token in tokens {
                    #expect(path.append(token, in: trie), "API key '\(key)' generation failed")
                }
                
                #expect(path.isAtTerminal(), "API key '\(key)' is not terminal")
            }
            
            // Required keys should be accessible
            for requiredKey in schema.required {
                let tokens = tokenizer.encode(requiredKey)
                #expect(trie.node(for: tokens)?.terminal == true, "Required API key '\(requiredKey)' not terminal")
            }
        }
        
        @Test func userProfileSchema() {
            let tokenizer = JSONTokenizer()
            
            // User profile JSON structure
            let profileKeys = [
                "id", "uuid", "username", "email", "firstName", "lastName", "displayName",
                "dateOfBirth", "age", "gender", "phoneNumber", "mobileNumber",
                "address", "streetAddress", "city", "state", "postalCode", "country",
                "preferences", "settings", "theme", "language", "timezone",
                "avatar", "profilePicture", "bio", "website", "socialLinks",
                "isActive", "isVerified", "isPublic", "accountType",
                "createdAt", "updatedAt", "lastLoginAt", "loginCount"
            ]
            
            let schema = SchemaMeta(
                keys: profileKeys,
                required: ["id", "username", "email", "firstName", "lastName"]
            )
            
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            #expect(trie.allKeys == Set(profileKeys))
            
            // Test constraint generation for user profile
            var generatedKeys: Set<String> = []
            
            for key in profileKeys.prefix(10) { // Test subset for performance
                let tokens = tokenizer.encode(key)
                var path = TokenTrie.Path(root: trie.root)
                
                for token in tokens {
                    let allowed = trie.getAllowedTokens(for: path)
                    #expect(allowed.contains(token), "Profile key '\(key)' token \(token) not allowed")
                    #expect(path.append(token, in: trie))
                }
                
                #expect(path.isAtTerminal())
                #expect(path.getKeyName() == key)
                generatedKeys.insert(key)
            }
            
            #expect(generatedKeys.count == 10)
        }
        
        @Test func configurationSchema() {
            let tokenizer = JSONTokenizer()
            
            // Configuration file structure
            let configKeys = [
                "version", "name", "description", "author", "license",
                "main", "scripts", "dependencies", "devDependencies", "peerDependencies",
                "engines", "os", "cpu", "private", "publishConfig",
                "repository", "url", "type", "bugs", "homepage",
                "keywords", "files", "bin", "man", "directories"
            ]
            
            let trie = TokenTrieBuilder.build(keys: configKeys, tokenizer: tokenizer)
            
            // Test that configuration keys can be properly constrained
            for key in configKeys {
                let tokens = tokenizer.encode(key)
                #expect(!tokens.isEmpty, "Config key '\(key)' has empty tokens")
                
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Config key '\(key)' is not terminal")
                #expect(node?.keyName == key)
                
                // Verify token-by-token generation
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    #expect(path.append(token, in: trie))
                }
                #expect(path.isAtTerminal())
            }
            
            // Test configuration-specific constraints
            let criticalKeys = ["name", "version", "main"]
            for key in criticalKeys {
                #expect(trie.allKeys.contains(key), "Critical config key '\(key)' missing")
            }
        }
        
        @Test func ecommerceSchema() {
            let tokenizer = JSONTokenizer()
            
            // E-commerce product schema
            let productKeys = [
                "id", "sku", "name", "title", "description", "shortDescription",
                "price", "salePrice", "regularPrice", "currency", "priceRange",
                "category", "categories", "tags", "brand", "manufacturer",
                "images", "thumbnail", "gallery", "videos",
                "variants", "size", "color", "material", "weight", "dimensions",
                "inStock", "stockCount", "availability", "backorder",
                "ratings", "reviews", "averageRating", "reviewCount",
                "shipping", "shippingClass", "taxClass", "taxStatus",
                "featured", "onSale", "virtual", "downloadable", "digital",
                "createdDate", "modifiedDate", "publishDate", "status"
            ]
            
            let schema = SchemaMeta(
                keys: productKeys,
                required: ["id", "name", "price", "category", "inStock"]
            )
            
            let trie = TokenTrieBuilder.build(from: schema, tokenizer: tokenizer)
            
            // Test e-commerce constraint generation
            #expect(trie.allKeys == Set(productKeys))
            
            // Required e-commerce fields should be constrainable
            for requiredKey in schema.required {
                let tokens = tokenizer.encode(requiredKey)
                let node = trie.node(for: tokens)
                #expect(node?.terminal == true, "Required e-commerce key '\(requiredKey)' not terminal")
                
                // Test generation path
                var path = TokenTrie.Path(root: trie.root)
                for token in tokens {
                    #expect(path.append(token, in: trie))
                }
                #expect(path.isAtTerminal())
            }
            
            // Test category keys (hierarchical structure)
            let categoryRelatedKeys = productKeys.filter { $0.contains("categor") }
            for key in categoryRelatedKeys {
                let tokens = tokenizer.encode(key)
                #expect(trie.node(for: tokens)?.terminal == true, "Category key '\(key)' not found")
            }
        }
    }
}
